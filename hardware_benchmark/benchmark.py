import torch
import time

# å®šä¹‰ä¸€ä¸ªè¶³å¤Ÿå¤§çš„çŸ©é˜µï¼Œè®©è®¡ç®—é‡è¾¾åˆ°äº¿çº§
SIZE = 4000

def run_test(device_name):
    device = torch.device(device_name)
    # åˆ›å»ºéšæœºçŸ©é˜µ
    a = torch.randn(SIZE, SIZE, device=device)
    b = torch.randn(SIZE, SIZE, device=device)
    
    # é¢„çƒ­ä¸€ä¸‹ï¼ˆé˜²æ­¢ç¬¬ä¸€æ¬¡è¿è¡Œçš„ç³»ç»Ÿå¼€é”€å½±å“ç»“æœï¼‰
    _ = torch.mm(a, b)
    if device_name == "mps": torch.mps.synchronize()
    
    # æ­£å¼è®¡æ—¶
    start = time.time()
    for _ in range(100): # è¿è¡Œ100æ¬¡å–å¹³å‡
        c = torch.mm(a, b)
    
    if device_name == "mps": torch.mps.synchronize()
    return (time.time() - start) / 10

print(f"ğŸ“Š æ­£åœ¨å¯¹æ¯” {SIZE}x{SIZE} çŸ©é˜µä¹˜æ³•æ€§èƒ½...")

# CPU æµ‹è¯•
cpu_time = run_test("cpu")
print(f"ğŸŒ CPU å¹³å‡è€—æ—¶: {cpu_time:.4f} ç§’")

# GPU (MPS) æµ‹è¯•
if torch.backends.mps.is_available():
    mps_time = run_test("mps")
    print(f"ğŸš€ MPS (GPU) å¹³å‡è€—æ—¶: {mps_time:.4f} ç§’")
    print(f"âœ¨ æå‡å€æ•°: {cpu_time / mps_time:.2f} å€")
else:
    print("âŒ æœªæ£€æµ‹åˆ° MPS åŠ é€Ÿ")